{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a500d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "\n",
    "\n",
    "# Cleaning function to remove unwanted special symbols and delimiters\n",
    "def clean_text(text):\n",
    "    # Remove special characters like hyphens, underscores, etc., and replace them with a single space\n",
    "    text = re.sub(r'[_\\-\\s]{2,}', ' ', text)  # Clean multiple underscores, hyphens, or spaces\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    return text.strip()\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "scam_df = pd.read_csv('phishing_email.csv')\n",
    "# Clean all the text before applying TF-IDF\n",
    "scam_df['text_combined_cleaned'] = scam_df['text_combined'].apply(clean_text)\n",
    "\n",
    "# Step 1: Data preprocessing\n",
    "X = scam_df['text_combined_cleaned'].fillna('')  # Handle missing text data\n",
    "y = scam_df['label']\n",
    "\n",
    "# Step 2: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Use TF-IDF to convert text to numerical features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Step 4: Train a logistic regression classification model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Uncomment below to train a random forest classification model instead\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "#y_pred = model.predict(X_test_tfidf)\n",
    "#print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "def extract_important_keywords(model, tfidf_vectorizer, top_n):\n",
    "    # Check if the model is a linear model (e.g., Logistic Regression)\n",
    "    if hasattr(model, 'coef_'):\n",
    "        coefficients = model.coef_.flatten()\n",
    "        # Select only the positive coefficients contributing to the positive class (label=1)\n",
    "        positive_indices = np.where(coefficients > 0)[0]\n",
    "        # Sort the positive coefficients in descending order\n",
    "        sorted_positive_indices = positive_indices[np.argsort(coefficients[positive_indices])[::-1][:top_n]]\n",
    "        important_keywords = np.array(tfidf_vectorizer.get_feature_names_out())[sorted_positive_indices]\n",
    "        important_weights = coefficients[sorted_positive_indices]\n",
    "\n",
    "        # Return a list of tuples containing keywords and their coefficients\n",
    "        important_keywords_with_weights = list(zip(important_keywords, important_weights))\n",
    "        \n",
    "        # Output the important keywords and their coefficients\n",
    "        #print(\"Top 40 Important Keywords and their Coefficients:\")\n",
    "        #for keyword, coef in important_keywords_with_weights:\n",
    "            #print(f\"{keyword}: {coef}\")\n",
    "        \n",
    "        return important_keywords_with_weights\n",
    "\n",
    "    # Check if the model is a tree-based model (e.g., Random Forest)\n",
    "    #elif hasattr(model, 'feature_importances_'):\n",
    "        #feature_importances = model.feature_importances_\n",
    "        #indices = np.argsort(feature_importances)[::-1][:top_n]\n",
    "        #important_keywords = np.array(tfidf_vectorizer.get_feature_names_out())[indices]\n",
    "        #important_weights = feature_importances[indices]\n",
    "\n",
    "        # Return a list of tuples containing keywords and their importance\n",
    "        #important_keywords_with_weights = list(zip(important_keywords, important_weights))\n",
    "        \n",
    "        # Output the important keywords and their importance\n",
    "        #print(\"Top 40 Important Keywords and their Importance:\")\n",
    "        #for keyword, importance in important_keywords_with_weights:\n",
    "            #print(f\"{keyword}: {importance}\")\n",
    "        \n",
    "        #return important_keywords_with_weights\n",
    "\n",
    "    # If the model type is not supported\n",
    "    else:\n",
    "        print(\"Model type not supported for keyword extraction.\")\n",
    "        return []\n",
    "\n",
    "# Call the function to extract important keywords along with their weights\n",
    "important_keywords_list = extract_important_keywords(model, tfidf_vectorizer, top_n=40)\n",
    "\n",
    "# Create a dictionary mapping words to categories\n",
    "word_category_mapping = {\n",
    "    'josemonkeyorg': 'Online Scam Phrases',\n",
    "    'cnncom': 'Online Scam Phrases',\n",
    "    'http': 'Online Scam Phrases',\n",
    "    'click': 'Online Scam Phrases',\n",
    "    'remove': 'Online Scam Phrases',\n",
    "    'choose': 'Online Scam Phrases',\n",
    "    'site': 'Online Scam Phrases',\n",
    "    \n",
    "    'investment': 'Financial Scam Phrases',\n",
    "    'account': 'Financial Scam Phrases',\n",
    "    'money': 'Financial Scam Phrases',\n",
    "    'statements': 'Financial Scam Phrases',\n",
    "    'payment': 'Financial Scam Phrases',\n",
    "    'transfer': 'Financial Scam Phrases',\n",
    "    'approved': 'Financial Scam Phrases',\n",
    "    'bank': 'Financial Scam Phrases',\n",
    "    \n",
    "    'viagra': 'Healthcare Scam Phrases',\n",
    "    'pills': 'Healthcare Scam Phrases',\n",
    "    'lose': 'Healthcare Scam Phrases',\n",
    "    'health': 'Healthcare Scam Phrases',\n",
    "    \n",
    "    'guaranteed': 'Counterfeit Product Phrases',\n",
    "    'replica': 'Counterfeit Product Phrases',\n",
    "    'custom': 'Counterfeit Product Phrases',\n",
    "    'huge': 'Counterfeit Product Phrases',\n",
    "    'watches': 'Counterfeit Product Phrases',\n",
    "    'quality': 'Counterfeit Product Phrases',\n",
    "    'rolex': 'Counterfeit Product Phrases',\n",
    "    'cable': 'Counterfeit Product Phrases',\n",
    "    \n",
    "    'love': 'Emotional Manipulation Phrases',\n",
    "    'professional': 'Emotional Manipulation Phrases',\n",
    "    'dear': 'Emotional Manipulation Phrases',\n",
    "    'sex': 'Emotional Manipulation Phrases',\n",
    "    'life': 'Emotional Manipulation Phrases'\n",
    "}\n",
    "\n",
    "# Example descriptions for each category\n",
    "category_descriptions = {\n",
    "    \"Online Scam Phrases\": \"Online Scam Phrases are commonly associated with scams that involve phishing websites, suspicious URLs, and prompts to click links. Scammers often trick users into visiting fraudulent sites by embedding links that appear legitimate but lead to malicious content.\",\n",
    "    \"Financial Scam Phrases\": \"Financial Scam Phrases frequently appear in scams that target individuals by impersonating financial institutions or promoting fake investment opportunities. Scammers use these words to exploit trust and deceive victims into giving up money or sensitive banking information.\",\n",
    "    \"Healthcare Scam Phrases\": \"Healthcare Scam Phrases are found in scams promoting counterfeit medications or fake health treatments. Common in email spam, these phrases lure victims with promises of weight loss, performance enhancement, or health benefits.\",\n",
    "    \"Counterfeit Product Phrases\": \"Counterfeit Product Phrases are indicative of scams that involve counterfeit goods, particularly luxury items like watches and electronics. Scammers use enticing words such as 'replica' or 'guaranteed' to promote fake products at attractive prices, often leading to low-quality or fraudulent purchases.\",\n",
    "    \"Emotional Manipulation Phrases\": \"Emotional Manipulation Phrases are found in romance scams and personal appeals. Scammers often use emotionally charged language to create trust or a sense of urgency, manipulating victims into sending money or personal information under false pretenses.\"\n",
    "}\n",
    "\n",
    "\n",
    "scam_categories = {\n",
    "    \"Online Scam Phrases\": {\"words\": {}, \"description\": category_descriptions[\"Online Scam Phrases\"]},\n",
    "    \"Financial Scam Phrases\": {\"words\": {}, \"description\": category_descriptions[\"Financial Scam Phrases\"]},\n",
    "    \"Healthcare Scam Phrases\": {\"words\": {}, \"description\": category_descriptions[\"Healthcare Scam Phrases\"]},\n",
    "    \"Counterfeit Product Phrases\": {\"words\": {}, \"description\": category_descriptions[\"Counterfeit Product Phrases\"]},\n",
    "    \"Emotional Manipulation Phrases\": {\"words\": {}, \"description\": category_descriptions[\"Emotional Manipulation Phrases\"]}\n",
    "}\n",
    "\n",
    "# Iterate over the important_keywords_list and allocate the words to the correct category\n",
    "for word, weight in important_keywords_list:\n",
    "    # Check if the word exists in the word_category_mapping dictionary\n",
    "    if word in word_category_mapping:\n",
    "        # Get the category the word belongs to\n",
    "        category = word_category_mapping[word]\n",
    "        # Add the word and its rounded weight to the appropriate category in the scam_categories dictionary\n",
    "        scam_categories[category][\"words\"][word] = round(weight, 2)\n",
    "\n",
    "# Save the scam_categories dictionary to a JSON file\n",
    "with open('wordcould_content.json', 'w') as json_file:\n",
    "    json.dump(scam_categories, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
